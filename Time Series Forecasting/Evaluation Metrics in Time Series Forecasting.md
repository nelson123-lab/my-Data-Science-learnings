Evaluation metrics in time series forecasting are used to assess the performance and accuracy of forecasting models. Here are some commonly used evaluation metrics in time series forecasting:

1. Mean Absolute Error (MAE): MAE measures the average absolute difference between the predicted values and the actual values. It provides a measure of the average magnitude of errors without considering their direction.

2. Root Mean Squared Error (RMSE): RMSE is similar to MAE but gives more weight to larger errors. It calculates the square root of the average of the squared differences between the predicted values and the actual values. RMSE is useful for penalizing larger errors more heavily.

3. Mean Absolute Percentage Error (MAPE): MAPE measures the average percentage difference between the predicted values and the actual values. It is particularly useful when you want to understand the relative error in forecasting.

4. Symmetric Mean Absolute Percentage Error (SMAPE): SMAPE is similar to MAPE but calculates the average percentage difference between the predicted and actual values, taking into account the average of the predicted and actual values. SMAPE is useful when the magnitude of the error is important.

5. Mean Absolute Scaled Error (MASE): MASE compares the forecast accuracy of a model to that of a naive baseline model. It measures the mean absolute error of the model divided by the mean absolute error of the baseline model. MASE values less than 1 indicate that the model performs better than the baseline.

